# Omniy ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã‚¬ã‚¤ãƒ‰

æœ€çµ‚æ›´æ–°æ—¥: 2025å¹´1æœˆ27æ—¥

## ğŸ¯ æ¦‚è¦

æœ¬æ–‡æ›¸ã¯ã€Omniy Instagramè‡ªå‹•æŠ•ç¨¿ã‚µãƒ¼ãƒ“ã‚¹ã®åŒ…æ‹¬çš„ãªç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆä½“åˆ¶ã®è¨­å®šæ–¹æ³•ã‚’å®šç¾©ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ã®å¯ç”¨æ€§ãƒ»æ€§èƒ½ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’ç¶™ç¶šçš„ã«ç›£è¦–ã—ã€å•é¡Œã®æ—©æœŸç™ºè¦‹ã¨è¿…é€Ÿãªå¯¾å¿œã‚’å®Ÿç¾ã—ã¾ã™ã€‚

## ğŸ“Š ç›£è¦–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    subgraph "Application Layer"
        A[Frontend Vue.js] --> B[Cloud Functions]
        B --> C[Firestore]
        B --> D[Instagram Graph API]
        B --> E[Stripe API]
    end
    
    subgraph "Monitoring Layer"
        F[Google Cloud Monitoring] --> G[Cloud Logging]
        F --> H[Error Reporting]
        F --> I[Cloud Trace]
        F --> J[Custom Metrics]
    end
    
    subgraph "Alerting Layer"
        K[Email Alerts] --> L[Slack Notifications]
        K --> M[PagerDuty]
        K --> N[SMS Alerts]
    end
    
    B --> F
    C --> F
```

---

## ğŸ”§ Google Cloud Monitoring è¨­å®š

### 1. Cloud Functions ç›£è¦–

#### 1.1 ã‚¨ãƒ©ãƒ¼ç‡ç›£è¦–
```yaml
# cloud-functions-error-rate.yaml
displayName: "Cloud Functions High Error Rate"
combiner: OR
conditions:
  - displayName: "Error rate > 5%"
    conditionThreshold:
      filter: |
        resource.type="cloud_function"
        metric.type="cloudfunctions.googleapis.com/function/execution_count"
        metric.label.status!="ok"
      comparison: COMPARISON_GREATER_THAN
      thresholdValue: 0.05
      duration: 300s
      aggregations:
        - alignmentPeriod: 60s
          perSeriesAligner: ALIGN_RATE
          crossSeriesReducer: REDUCE_SUM
```

#### 1.2 å®Ÿè¡Œæ™‚é–“ç›£è¦–
```yaml
# cloud-functions-latency.yaml
displayName: "Cloud Functions High Latency"
conditions:
  - displayName: "P95 execution time > 10s"
    conditionThreshold:
      filter: |
        resource.type="cloud_function"
        metric.type="cloudfunctions.googleapis.com/function/execution_times"
      comparison: COMPARISON_GREATER_THAN
      thresholdValue: 10000
      duration: 300s
      aggregations:
        - alignmentPeriod: 60s
          perSeriesAligner: ALIGN_PERCENTILE_95
```

#### 1.3 ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
```yaml
# cloud-functions-memory.yaml
displayName: "Cloud Functions High Memory Usage"
conditions:
  - displayName: "Memory utilization > 80%"
    conditionThreshold:
      filter: |
        resource.type="cloud_function"
        metric.type="cloudfunctions.googleapis.com/function/user_memory_bytes"
      comparison: COMPARISON_GREATER_THAN
      thresholdValue: 0.8
      duration: 300s
```

### 2. Firestore ç›£è¦–

#### 2.1 èª­ã¿å–ã‚Šãƒ»æ›¸ãè¾¼ã¿æ“ä½œç›£è¦–
```yaml
# firestore-operations.yaml
displayName: "Firestore High Operation Rate"
conditions:
  - displayName: "Document reads > 1000/min"
    conditionThreshold:
      filter: |
        resource.type="datastore_database"
        metric.type="firestore.googleapis.com/api/request_count"
        metric.label.op_type="read"
      comparison: COMPARISON_GREATER_THAN
      thresholdValue: 1000
      duration: 60s
```

#### 2.2 æ¥ç¶šã‚¨ãƒ©ãƒ¼ç›£è¦–
```yaml
# firestore-errors.yaml
displayName: "Firestore Connection Errors"
conditions:
  - displayName: "Error rate > 1%"
    conditionThreshold:
      filter: |
        resource.type="datastore_database"
        metric.type="firestore.googleapis.com/api/request_count"
        metric.label.response_code!="200"
      comparison: COMPARISON_GREATER_THAN
      thresholdValue: 0.01
      duration: 300s
```

### 3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å›ºæœ‰ç›£è¦–

#### 3.1 æŠ•ç¨¿å®Ÿè¡ŒæˆåŠŸç‡
```javascript
// functions/src/utils/metrics.ts
import { Monitoring } from '@google-cloud/monitoring';

const monitoring = new Monitoring.MetricServiceClient();
const projectId = 'omniy-prod';

export class MetricsCollector {
  async recordPostExecution(success: boolean, accountId: string) {
    const request = {
      name: `projects/${projectId}`,
      timeSeries: [{
        metric: {
          type: 'custom.googleapis.com/instagram/post_execution',
          labels: {
            'account_id': accountId,
            'status': success ? 'success' : 'failure'
          }
        },
        resource: {
          type: 'global'
        },
        points: [{
          interval: {
            endTime: {
              seconds: Math.floor(Date.now() / 1000)
            }
          },
          value: {
            int64Value: 1
          }
        }]
      }]
    };

    await monitoring.createTimeSeries(request);
  }

  async recordAPILatency(endpoint: string, latencyMs: number) {
    const request = {
      name: `projects/${projectId}`,
      timeSeries: [{
        metric: {
          type: 'custom.googleapis.com/api/latency',
          labels: {
            'endpoint': endpoint
          }
        },
        resource: {
          type: 'global'
        },
        points: [{
          interval: {
            endTime: {
              seconds: Math.floor(Date.now() / 1000)
            }
          },
          value: {
            doubleValue: latencyMs
          }
        }]
      }]
    };

    await monitoring.createTimeSeries(request);
  }

  async recordUserActivity(action: string, userId: string) {
    const request = {
      name: `projects/${projectId}`,
      timeSeries: [{
        metric: {
          type: 'custom.googleapis.com/user/activity',
          labels: {
            'action': action,
            'user_id': userId
          }
        },
        resource: {
          type: 'global'
        },
        points: [{
          interval: {
            endTime: {
              seconds: Math.floor(Date.now() / 1000)
            }
          },
          value: {
            int64Value: 1
          }
        }]
      }]
    };

    await monitoring.createTimeSeries(request);
  }
}
```

#### 3.2 ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨­å®š
```yaml
# custom-metrics-alerts.yaml
displayName: "Instagram Post Success Rate"
conditions:
  - displayName: "Success rate < 95%"
    conditionThreshold:
      filter: |
        metric.type="custom.googleapis.com/instagram/post_execution"
        metric.label.status="success"
      comparison: COMPARISON_LESS_THAN
      thresholdValue: 0.95
      duration: 600s
      aggregations:
        - alignmentPeriod: 300s
          perSeriesAligner: ALIGN_RATE
          crossSeriesReducer: REDUCE_SUM
```

---

## ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥è¨­å®š

### 1. é€šçŸ¥ãƒãƒ£ãƒ³ãƒãƒ«è¨­å®š

#### 1.1 ãƒ¡ãƒ¼ãƒ«é€šçŸ¥
```bash
# Eãƒ¡ãƒ¼ãƒ«é€šçŸ¥ãƒãƒ£ãƒ³ãƒãƒ«ä½œæˆ
gcloud alpha monitoring channels create \
  --notification-channel-config='{
    "type": "email",
    "displayName": "Operations Team Email",
    "description": "Primary email for operations alerts",
    "labels": {
      "email_address": "alerts@omniy.jp"
    }
  }'
```

#### 1.2 Slacké€šçŸ¥
```bash
# Slacké€šçŸ¥ãƒãƒ£ãƒ³ãƒãƒ«ä½œæˆ
gcloud alpha monitoring channels create \
  --notification-channel-config='{
    "type": "slack",
    "displayName": "Slack Operations Channel",
    "description": "Slack #alerts channel",
    "labels": {
      "channel_name": "#alerts",
      "url": "https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX"
    }
  }'
```

#### 1.3 SMSé€šçŸ¥ï¼ˆç·Šæ€¥æ™‚ï¼‰
```bash
# SMSé€šçŸ¥ãƒãƒ£ãƒ³ãƒãƒ«ä½œæˆ
gcloud alpha monitoring channels create \
  --notification-channel-config='{
    "type": "sms",
    "displayName": "Emergency SMS",
    "description": "Emergency SMS for critical alerts",
    "labels": {
      "number": "+81-90-1234-5678"
    }
  }'
```

### 2. ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒªã‚·ãƒ¼ã®éšå±¤åŒ–

#### ãƒ¬ãƒ™ãƒ«1: æƒ…å ± (Info)
- **é€šçŸ¥å…ˆ**: ãƒ¡ãƒ¼ãƒ«ã€Slack
- **å¯¾å¿œæ™‚é–“**: ç¿Œå–¶æ¥­æ—¥
- **ä¾‹**: è»½å¾®ãªæ€§èƒ½åŠ£åŒ–ã€ä½¿ç”¨é‡è­¦å‘Š

#### ãƒ¬ãƒ™ãƒ«2: è­¦å‘Š (Warning)  
- **é€šçŸ¥å…ˆ**: ãƒ¡ãƒ¼ãƒ«ã€Slackã€æ‹…å½“è€…ã¸ã®ç›´æ¥é€£çµ¡
- **å¯¾å¿œæ™‚é–“**: 2æ™‚é–“ä»¥å†…
- **ä¾‹**: API ã‚¨ãƒ©ãƒ¼ç‡ä¸Šæ˜‡ã€æŠ•ç¨¿æˆåŠŸç‡ä½ä¸‹

#### ãƒ¬ãƒ™ãƒ«3: ç·Šæ€¥ (Critical)
- **é€šçŸ¥å…ˆ**: ãƒ¡ãƒ¼ãƒ«ã€Slackã€SMSã€é›»è©±
- **å¯¾å¿œæ™‚é–“**: 15åˆ†ä»¥å†…
- **ä¾‹**: ã‚µãƒ¼ãƒ“ã‚¹å…¨åœæ­¢ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¾µå®³

### 3. é€šçŸ¥è¨­å®šä¾‹

```yaml
# critical-alert-policy.yaml
displayName: "Critical System Failure"
alertStrategy:
  autoClose: 604800s  # 7 days
notificationChannels:
  - "projects/omniy-prod/notificationChannels/email-ops"
  - "projects/omniy-prod/notificationChannels/slack-alerts"
  - "projects/omniy-prod/notificationChannels/sms-emergency"
documentation:
  content: |
    ## Critical System Failure Detected
    
    This alert indicates a critical system failure that requires immediate attention.
    
    ### Immediate Actions:
    1. Check the incident response playbook
    2. Verify system status dashboard
    3. Initiate emergency response if needed
    
    ### Escalation:
    - Level 1: Operations team (immediate)
    - Level 2: Engineering lead (15 minutes)
    - Level 3: Management (30 minutes)
  mimeType: "text/markdown"
```

---

## ğŸ“ˆ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š

### 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

```json
{
  "displayName": "Omniy Executive Dashboard",
  "mosaicLayout": {
    "tiles": [
      {
        "width": 6,
        "height": 3,
        "widget": {
          "title": "Overall Service Health",
          "scorecard": {
            "timeSeriesQuery": {
              "timeSeriesFilter": {
                "filter": "metric.type=\"compute.googleapis.com/instance/up\"",
                "aggregation": {
                  "alignmentPeriod": "60s",
                  "perSeriesAligner": "ALIGN_MEAN"
                }
              }
            },
            "gaugeView": {
              "lowerBound": 0.0,
              "upperBound": 1.0
            }
          }
        }
      },
      {
        "width": 6,
        "height": 3,
        "widget": {
          "title": "Daily Active Users",
          "xyChart": {
            "dataSets": [{
              "timeSeriesQuery": {
                "timeSeriesFilter": {
                  "filter": "metric.type=\"custom.googleapis.com/user/activity\"",
                  "aggregation": {
                    "alignmentPeriod": "3600s",
                    "perSeriesAligner": "ALIGN_SUM"
                  }
                }
              }
            }]
          }
        }
      }
    ]
  }
}
```

### 2. é‹ç”¨ãƒãƒ¼ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

```json
{
  "displayName": "Operations Dashboard",
  "mosaicLayout": {
    "tiles": [
      {
        "width": 4,
        "height": 3,
        "widget": {
          "title": "Cloud Functions Error Rate",
          "xyChart": {
            "dataSets": [{
              "timeSeriesQuery": {
                "timeSeriesFilter": {
                  "filter": "resource.type=\"cloud_function\" metric.type=\"cloudfunctions.googleapis.com/function/execution_count\"",
                  "aggregation": {
                    "alignmentPeriod": "60s",
                    "perSeriesAligner": "ALIGN_RATE",
                    "crossSeriesReducer": "REDUCE_SUM"
                  }
                }
              }
            }]
          }
        }
      },
      {
        "width": 4,
        "height": 3,
        "widget": {
          "title": "Instagram API Success Rate",
          "xyChart": {
            "dataSets": [{
              "timeSeriesQuery": {
                "timeSeriesFilter": {
                  "filter": "metric.type=\"custom.googleapis.com/instagram/post_execution\"",
                  "aggregation": {
                    "alignmentPeriod": "300s",
                    "perSeriesAligner": "ALIGN_RATE"
                  }
                }
              }
            }]
          }
        }
      }
    ]
  }
}
```

### 3. é–‹ç™ºãƒãƒ¼ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

```json
{
  "displayName": "Development Dashboard",
  "mosaicLayout": {
    "tiles": [
      {
        "width": 6,
        "height": 4,
        "widget": {
          "title": "Application Latency Distribution",
          "xyChart": {
            "dataSets": [{
              "timeSeriesQuery": {
                "timeSeriesFilter": {
                  "filter": "metric.type=\"custom.googleapis.com/api/latency\"",
                  "aggregation": {
                    "alignmentPeriod": "60s",
                    "perSeriesAligner": "ALIGN_PERCENTILE_95"
                  }
                }
              }
            }]
          }
        }
      },
      {
        "width": 6,
        "height": 4,
        "widget": {
          "title": "Error Distribution by Function",
          "xyChart": {
            "dataSets": [{
              "timeSeriesQuery": {
                "timeSeriesFilter": {
                  "filter": "resource.type=\"cloud_function\" metric.type=\"logging.googleapis.com/log_entry_count\" resource.label.function_name!=\"\"",
                  "aggregation": {
                    "alignmentPeriod": "300s",
                    "perSeriesAligner": "ALIGN_SUM",
                    "crossSeriesReducer": "REDUCE_SUM",
                    "groupByFields": ["resource.label.function_name"]
                  }
                }
              }
            }]
          }
        }
      }
    ]
  }
}
```

---

## ğŸ” ãƒ­ã‚°ç®¡ç†

### 1. æ§‹é€ åŒ–ãƒ­ã‚°è¨­å®š

```javascript
// functions/src/utils/logger.ts
import { createLogger, format, transports } from 'winston';

const logger = createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: format.combine(
    format.timestamp(),
    format.errors({ stack: true }),
    format.json()
  ),
  transports: [
    new transports.Console()
  ]
});

export class AppLogger {
  static info(message: string, meta?: any) {
    logger.info(message, {
      ...meta,
      service: 'omniy',
      version: process.env.VERSION || 'unknown'
    });
  }

  static error(message: string, error?: Error, meta?: any) {
    logger.error(message, {
      ...meta,
      error: error?.message,
      stack: error?.stack,
      service: 'omniy',
      version: process.env.VERSION || 'unknown'
    });
  }

  static audit(action: string, userId: string, details?: any) {
    logger.info('AUDIT', {
      action,
      userId,
      details,
      timestamp: new Date().toISOString(),
      service: 'omniy',
      type: 'audit'
    });
  }
}
```

### 2. ãƒ­ã‚°ã‚¢ã‚°ãƒªã‚²ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š

```bash
# Cloud Logging ã‚·ãƒ³ã‚¯è¨­å®š
gcloud logging sinks create omniy-audit-sink \
  bigquery.googleapis.com/projects/omniy-prod/datasets/audit_logs \
  --log-filter='jsonPayload.type="audit"'

gcloud logging sinks create omniy-error-sink \
  pubsub.googleapis.com/projects/omniy-prod/topics/error-notifications \
  --log-filter='severity>=ERROR'
```

### 3. ãƒ­ã‚°ä¿æŒãƒãƒªã‚·ãƒ¼

```bash
# ãƒ­ã‚°ä¿æŒæœŸé–“è¨­å®š
gcloud logging buckets update _Default \
  --location=global \
  --retention-days=90

# ç›£æŸ»ãƒ­ã‚°ã®é•·æœŸä¿æŒ
gcloud logging buckets create audit-logs-long-term \
  --location=global \
  --retention-days=2555  # 7å¹´é–“
```

---

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–

### 1. ä¸æ­£ã‚¢ã‚¯ã‚»ã‚¹æ¤œçŸ¥

```yaml
# security-alerts.yaml
displayName: "Suspicious Authentication Activity"
conditions:
  - displayName: "Failed login attempts > 10/minute"
    conditionThreshold:
      filter: |
        resource.type="cloud_function"
        jsonPayload.action="login_failed"
      comparison: COMPARISON_GREATER_THAN
      thresholdValue: 10
      duration: 60s
```

### 2. APIä¹±ç”¨æ¤œçŸ¥

```javascript
// functions/src/middleware/rateLimiting.ts
import { Request, Response, NextFunction } from 'express';
import { AppLogger } from '../utils/logger';

export function rateLimitingMiddleware(req: Request, res: Response, next: NextFunction) {
  const userId = req.user?.uid;
  const endpoint = req.path;
  const clientIP = req.ip;

  // ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
  const requestCount = getRequestCount(userId, endpoint, clientIP);
  
  if (requestCount > RATE_LIMITS[endpoint]) {
    AppLogger.audit('RATE_LIMIT_EXCEEDED', userId, {
      endpoint,
      clientIP,
      requestCount
    });
    
    // ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
    sendSecurityAlert('Rate limit exceeded', {
      userId,
      endpoint,
      clientIP,
      requestCount
    });
    
    return res.status(429).json({ error: 'Rate limit exceeded' });
  }

  next();
}
```

### 3. ãƒ‡ãƒ¼ã‚¿æ¼æ´©ç›£è¦–

```bash
# Cloud DLP APIè¨­å®š
gcloud dlp job-triggers create \
  --location=global \
  --config='{
    "displayName": "PII Detection in Logs",
    "triggers": [{
      "schedule": {
        "recurrencePeriodDuration": "86400s"
      }
    }],
    "inspectJob": {
      "inspectConfig": {
        "infoTypes": [
          {"name": "EMAIL_ADDRESS"},
          {"name": "PHONE_NUMBER"},
          {"name": "CREDIT_CARD_NUMBER"}
        ]
      },
      "storageConfig": {
        "cloudStorageOptions": {
          "fileSet": {
            "url": "gs://omniy-prod-logs/*"
          }
        }
      }
    }
  }'
```

---

## ğŸ“± ãƒ¢ãƒã‚¤ãƒ«ãƒ»å¤–éƒ¨ç›£è¦–

### 1. å¤–éƒ¨ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹é€£æº

```javascript
// Uptime monitoring setup
const uptimeCheck = {
  displayName: 'Omniy Homepage Check',
  monitoredResource: {
    type: 'uptime_url',
    labels: {
      project_id: 'omniy-prod',
      host: 'omniy.app'
    }
  },
  httpCheck: {
    path: '/',
    port: 443,
    useSsl: true,
    validateSsl: true
  },
  period: '60s',
  timeout: '10s'
};
```

### 2. APM (Application Performance Monitoring)

```javascript
// Cloud Traceè¨­å®š
import { NodeSDK } from '@opentelemetry/auto-instrumentations-node';
import { getNodeAutoInstrumentations } from '@opentelemetry/auto-instrumentations-node';
import { Resource } from '@opentelemetry/resources';
import { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';

const sdk = new NodeSDK({
  resource: new Resource({
    [SemanticResourceAttributes.SERVICE_NAME]: 'omniy',
    [SemanticResourceAttributes.SERVICE_VERSION]: process.env.VERSION || '1.0.0',
  }),
  instrumentations: [getNodeAutoInstrumentations()],
});

sdk.start();
```

---

## ğŸ›ï¸ é‹ç”¨æ‰‹é †

### 1. æ—¥æ¬¡ç›£è¦–ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```markdown
## Daily Operations Checklist

### Morning (9:00 AM)
- [ ] ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
- [ ] å‰æ—¥ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] æŠ•ç¨¿å®Ÿè¡ŒæˆåŠŸç‡ã®ç¢ºèª
- [ ] ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã®ç¢ºèª
- [ ] äºˆå®šãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä½œæ¥­ã®ç¢ºèª

### Evening (6:00 PM)  
- [ ] æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®ç¢ºèª
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆçŠ¶æ³ã®æ•´ç†
- [ ] ç¿Œæ—¥ã®äºˆå®šç¢ºèª
- [ ] ã‚ªãƒ³ã‚³ãƒ¼ãƒ«æ‹…å½“è€…ã¸ã®å¼•ãç¶™ã
```

### 2. é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ

```javascript
// Weekly report generation
async function generateWeeklyReport() {
  const metrics = await collectWeeklyMetrics();
  
  const report = {
    period: `${startDate} - ${endDate}`,
    summary: {
      totalUsers: metrics.activeUsers,
      totalPosts: metrics.postsExecuted,
      successRate: metrics.successRate,
      averageLatency: metrics.averageLatency
    },
    incidents: await getIncidents(startDate, endDate),
    performance: {
      uptimePercentage: metrics.uptime,
      errorRate: metrics.errorRate,
      p95Latency: metrics.p95Latency
    },
    recommendations: generateRecommendations(metrics)
  };

  await sendReportToTeam(report);
}
```

### 3. æœˆæ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹

```markdown
## Monthly Review Process

### SLI/SLO Analysis
- Availability: Target 99.9%, Actual: [X]%
- Latency: Target <1000ms P95, Actual: [X]ms
- Error Rate: Target <0.1%, Actual: [X]%

### Capacity Planning
- User growth trend analysis
- Resource utilization trends
- Cost optimization opportunities

### Incident Review
- Total incidents: [X]
- MTTR improvement: [X]%
- Root cause analysis summary

### Action Items
- [ ] Infrastructure improvements
- [ ] Monitoring enhancements  
- [ ] Process optimizations
```

---

## ğŸ”— é–¢é€£ãƒ„ãƒ¼ãƒ«ãƒ»ãƒªã‚½ãƒ¼ã‚¹

### ç›£è¦–ãƒ„ãƒ¼ãƒ«
- **Google Cloud Monitoring**: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ
- **Cloud Logging**: ãƒ­ã‚°é›†ç´„ãƒ»åˆ†æ
- **Error Reporting**: ã‚¨ãƒ©ãƒ¼è¿½è·¡
- **Cloud Trace**: åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°

### å¤–éƒ¨ãƒ„ãƒ¼ãƒ«
- **Slack**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šçŸ¥
- **PagerDuty**: ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†
- **Grafana**: å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- **BigQuery**: ãƒ­ã‚°åˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆ

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [éšœå®³å¯¾å¿œæ‰‹é †æ›¸](./INCIDENT_RESPONSE.md)
- [é‹ç”¨æ‰‹é †æ›¸](./OPERATIONS.md)
- [æŠ€è¡“ä»•æ§˜æ›¸](./TECHNICAL_SPECIFICATIONS.md)

---

**ä½œæˆè€…**: DevOps ãƒãƒ¼ãƒ   
**æ‰¿èªè€…**: CTO  
**æ¬¡å›è¦‹ç›´ã—**: 2025å¹´4æœˆ27æ—¥